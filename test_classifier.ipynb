{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Type Classifier\n",
    "Classify cell type images from Bo Sun's Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import label_image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_list(folder):\n",
    "    image_list = {}\n",
    "    for directory in glob.glob(folder+'/*/'):\n",
    "        images = []\n",
    "        for filename in glob.glob(str(directory)+'*.jpg'): #assuming jpg\n",
    "            images.append(filename)\n",
    "        image_list.update({str(directory[directory.find('\\\\')+1:directory.rfind('\\\\')]):images})\n",
    "    return image_list\n",
    "\n",
    "def classify_cells(image_directory,model_file, \n",
    "                   label_file= \"output_files/output_labels.txt\", \n",
    "                   input_height=224, \n",
    "                   input_width=224,\n",
    "                   input_mean=0,\n",
    "                   input_std=255, \n",
    "                   input_layer='Placeholder',\n",
    "                   output_layer= 'final_result'):    \n",
    "    print('\\nClassifying directory...'+str(image_directory),'....')\n",
    "    image_list = get_image_list(image_directory)\n",
    "    graph = label_image.load_graph(model_file)\n",
    "    \n",
    "    #dict of validation images.\n",
    "    val_set = {}\n",
    "    print('reading images....')\n",
    "    for key in image_list.keys():\n",
    "        print(key+'.....',end='')\n",
    "        val_images = []\n",
    "        for file_name in image_list[key]:\n",
    "            val_images.append(label_image.read_tensor_from_image_file(\n",
    "                file_name,\n",
    "                input_height=input_height,\n",
    "                input_width=input_width,\n",
    "                input_mean=input_mean,\n",
    "                input_std=input_std))\n",
    "        val_set.update({str(key):val_images})\n",
    "        print('.....done')\n",
    "\n",
    "\n",
    "    input_name = \"import/\" + input_layer\n",
    "    output_name = \"import/\" + output_layer\n",
    "    input_operation = graph.get_operation_by_name(input_name)\n",
    "    output_operation = graph.get_operation_by_name(output_name)\n",
    "    \n",
    "    print('making predictions....')\n",
    "    predictions = {}\n",
    "    for key in val_set.keys():\n",
    "        print(key+'.....',end='')\n",
    "        val_pred = []\n",
    "        for img in val_set[key]:\n",
    "            with tf.Session(graph=graph) as sess:\n",
    "                results = sess.run(output_operation.outputs[0], {\n",
    "                input_operation.outputs[0]: img\n",
    "                })\n",
    "                results = np.squeeze(results)\n",
    "\n",
    "            val_pred.append(results.argsort()[-5:][::-1][0])\n",
    "        predictions.update({key:val_pred})\n",
    "        print('.....done')\n",
    "    labels = label_image.load_labels(label_file)\n",
    "    return predictions, labels\n",
    "\n",
    "def confusion_matrix(predictions,labels,title=None):\n",
    "    n=len(labels)\n",
    "    confusion_matrix = np.zeros((n,n), dtype=np.float)\n",
    "\n",
    "    pred_scores=[]\n",
    "    for i,ctype in enumerate(labels):\n",
    "        err,num = 0.0,0\n",
    "        for pred in predictions[ctype]:\n",
    "            confusion_matrix[pred,i]+=1/len(predictions[ctype])\n",
    "            num+=1\n",
    "            if(pred!=i):\n",
    "                err+=1\n",
    "        pred_scores.append(((num-err)/num,num))\n",
    "\n",
    "    for i,label in enumerate(labels):\n",
    "        print(label,'= ', str(round(pred_scores[i][0]*100,1))+'%,',pred_scores[i][1],'samples')\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cfm = ax.matshow(confusion_matrix, cmap=plt.cm.get_cmap('hot'))\n",
    "    cbar = fig.colorbar(cfm)\n",
    "\n",
    "    ax.set_xlabel('Cell Type', fontsize=20)\n",
    "    ax.set_ylabel('Prediction', fontsize=20)\n",
    "    ax.set_xticklabels(['']+labels, fontsize=12)\n",
    "    ax.set_yticklabels(['']+labels, fontsize=12)\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.labelpad = 20\n",
    "    ax.yaxis.labelpad = 20\n",
    "\n",
    "    fig.tight_layout(pad=0, w_pad=1.5, h_pad=3)\n",
    "    fig.set_figheight(10)\n",
    "    fig.set_figwidth(10)\n",
    "    fig.suptitle(title, fontsize=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available Trained models\n",
    "# If not available in repo, first generate using retrain_helper.ipynb\n",
    "inception_v1 = \"output_files/output_graph_inception_v1.pb\" # Final Test Accuracy: 90.0%\n",
    "inception_v1_p = \"output_files/output_graph_inception_v1_partial.pb\" # Final Test Accuracy: 89.0%\n",
    "inception_v2 = \"output_files/output_graph_inception_v2.pb\" # Final Test Accuracy: 90.0%. Not available in repo.\n",
    "inception_v3 = \"output_files/output_graph_inception_v3.pb\" # Final Test Accuracy: 94.3%. Not available in repo.\n",
    "mobilenet_v1 = 'output_graph_mobilenet_v1.pb' # Final Test Accuracy: 94.3% \n",
    "mobilenet_v2 = 'output_graph_mobilenet_v2.pb' # Final Test Accuracy: 92.2% \n",
    "inception_resnet_v2 = 'output_graph_inception_resnet_v2.pb' # Final Test Accuracy: 86.4%. Not available in repo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose directory of images to classify and Model to use for classification (model_file)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_dir = 'unseen_validation'\n",
    "train_dir = 'partial_cell_type_images'\n",
    "model_file = inception_v1_p\n",
    "\n",
    "# other paramaters with default values\n",
    "label_file = \"output_files/output_labels.txt\"\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "input_mean = 0\n",
    "input_std = 255\n",
    "input_layer = 'Placeholder'\n",
    "output_layer = 'final_result'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying directory:  unseen_validation ....\n",
      "reading images....\n",
      "actinedge..........done\n",
      "filopodia..........done\n",
      "hemisphere..........done\n",
      "lamellipodia..........done\n",
      "smallbleb..........done\n",
      "making predictions....\n",
      "actinedge....."
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (13, 1, 224, 224, 3) for Tensor 'import/Placeholder:0', which has shape '(?, 224, 224, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-40c37cd88834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Unseen Validation Set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0munseen_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munseen_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-2167f91b2c98>\u001b[0m in \u001b[0;36mclassify_cells\u001b[1;34m(image_directory, model_file, label_file, input_height, input_width, input_mean, input_std, input_layer, output_layer)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             results = sess.run(output_operation.outputs[0], {\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0minput_operation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             })\n\u001b[0;32m     53\u001b[0m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1111\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1112\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (13, 1, 224, 224, 3) for Tensor 'import/Placeholder:0', which has shape '(?, 224, 224, 3)'"
     ]
    }
   ],
   "source": [
    "#Unseen Validation Set\n",
    "unseen_predict, labels = classify_cells(unseen_dir,model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying directory:  partial_cell_type_images ....\n",
      "reading images....\n",
      "actinedge..........done\n",
      "filopodia..........done\n",
      "hemisphere..........done\n",
      "lamellipodia..........done\n",
      "smallbleb..........done\n",
      "making predictions....\n",
      "actinedge..........done\n",
      "filopodia..........done\n",
      "hemisphere..........done\n",
      "lamellipodia..........done\n",
      "smallbleb..........done\n"
     ]
    }
   ],
   "source": [
    "#Training Set\n",
    "train_predict, labels = classify_cells(train_dir,model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unseen_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0cb9c79d1921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munseen_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Unseen Validation Set'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'unseen_predict' is not defined"
     ]
    }
   ],
   "source": [
    "confusion_matrix(unseen_predict, labels, title='Unseen Validation Set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(train_predict, labels, title='Training Set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
